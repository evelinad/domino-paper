\section{A high-level language for data-plane algorithms}
\label{s:language}
%% A closer inspection of these
%%algorithms shows us that the algorithms are characterized by two distinguishing
%%features: a reliance on persistant state and an irregular control flow, both of
%%which make them challenging to implement in hardware and hence in P4 given its
%%low-level nature.
%%
%%As previously described, data-plane algorithms are characterized by an
%%irregular control flow and extensive use of stateful processing. Based on these
%%observations, this section proposes a language to express these algorithms.
%% Alvin: Can you take a stab at easing into this section better.

In this section we describe \pktlanguage, our language for expressing 
data-plane algorithms. The design of \pktlanguage is based on two principles:

\paragraph{A packet-oriented abstraction} 
Each \pktlanguage program is structured using
{\em packet functions}, where each function takes in a single packet
and a set of variables representing the state of the switch as input.
This design is based on the observation that many data-plane algorithms can
be expressed as ones that process each packet individually given the current 
state of the switch. Examples include XXX, and XXX. \ac{are packet functions
supposed to return anything? or do they modify the packet in place? how to 
express things like dropping the input packet?}
We believe this abstraction allows network operators to easily structure
and reason about their algorithms.

\paragraph{Transaction-based semantics} 
To avoid network operators from the need to reason about different execution
paradigms, each statement in \pktlanguage is executed sequentially.
Furthermore, each \pktlanguage packet function is intended to be executed
as a single transaction without any interruption. We adopted this design
from the widespread use of transactions 
in packet processing for software-router platforms. For instance,
Click's Element abstraction~\cite{click} specifies packet processing as
a method invocation that isn't pre-empted.  The Linux qdisc
subsystem~\cite{qdisc} exposes an enqueue and dequeue method that specific
algorithms can implement. Intel's IXP architecture for NPUs uses a construct
resembling transactions called a Packet-Processing Stage
(PPS)~\cite{npu} to express packet processing code.

With that in mind, Figure~\ref{fig:language} shows the grammar of \pktlanguage.
As an imperative language, the language constructs are mostly standard.
Notable features include the declaration of stateful variables outside of each
packet function, where such variables represent the state of the switch 
(e.g., XXX, and XXX) that are accessible inside each packet function, and 
modeling of the packet header \ac{check} fields as members of the {\tt Packet} class,
to be defined as part of the program.
The language does not have any looping constructs or memory allocation, 
as they cannot be easily implemented
in network hardware \ac{check if true}. Furthermore,
we currently restrict stateful variables and packet fields to be primitive
values (i.e., no arrays or structures).

\begin{figure}
\begin{small}
\begin{lstlisting}
v $\in$ variables ::=
  <stateful vars> | pkt.f | <constants>
op $\in$ binary ops ::= + | - | * | < | == | ! | && | || 
s $\in$ statements ::= 
  v$_1$ op v$_2$; | if (v$_1$) { s$_1$; } else { s$_2$; } | s$_1$ ; s$_2$ 
f $\in$ packet function ::= 
  <function name>(Packet pkt) { s }
p $\in$ program ::=
  <stateful vars decl> <packet fields decl> f
\end{lstlisting}
\end{small}
\label{fig:language}
\caption{\pktlanguage grammar}
\end{figure}


As an example, \ref{fig:flow}(a) \ac{can you add labels to the figure} shows
the body of a packet function written using 6 lines of \pktlanguage code
that implements load balancing using flowlet
switching~\cite{flowlets}.


% old text below
\if 0

To motivate a language for these algorithms, we first observe that most, if not all
data-plane algorithm can be expressed as a function that takes in a single
packet and a set of persistent state variables as input. This function then
runs to completion without interruption, modifying the packet and the
persistent state variables in the process. Further, conceptually, only one
packet is processed by this function at any given instant.

This view of data-plane algorithms suggests a natural way to structure them: as
transactions where a function specifies all the required state manipulation and
control flow required for packet processing. The use of transactions is
widespread in packet processing for software-router platforms. For instance,
Click's Element abstraction~\cite{click} specifies packet processing as
a method invocation that isn't pre-empted.  The Linux qdisc
subsystem~\cite{qdisc} exposes an enqueue and dequeue method that specific
algorithms can implement. Intel's IXP architecture for NPUs uses a construct
resembling transactions called a Packet-Processing Stage
(PPS)~\cite{npu} to express packet processing code.
% https://github.com/torvalds/linux/blob/master/net/sched/sch_codel.c#L256

Relative to these prior systems, our contribution is in observing that
transactions can be profitably used to express data-plane algorithms for
high-speed line-rate switches as well. Realizing this practically requires us
to design a language that expresses packet processing within the body of the
transaction. A good language would strike the right balance between ease of
expression and ease of implementation. Programmable hardware switches
---although a significant advance over their fixed-function counterparts---are
still very restricted in the processing that they do on every packet. This
restriction is required to remain competitive with fixed-function switches.

Based on these observations, we describe our language for packet processing
(Figure~\ref{fig:language}). Our language is a heavily constrained subset of C
that removes all iterative constructs (while, do-while, for, break, continue),
arrays, heaps, and memory allocation. State variables are represented as global
variables. We permit structures to represent packet processing alone, and immediately
desugar these to scalar variables (\S\ref{s:compiler}).

Forbidding loops and other sources of variable performance like memory
allocation, and array scans allows the user to only express code whose
execution latency can be bounded at compile time.  While this may seem overly
restrictive, this is required for the underlying architecture
(\S\ref{s:architecture}), which has deterministic performance regardless of the
traffic pattern or program being run.

\fi

%% Anirudh: Not sure if the text below makes sense/fits.
%% This results in a different set of
%% tradeoffs than what programmers are typically used to: a larger program does
%% not take longer to run. Instead, it may not run at all or might need to be
%% approximated until it can run (\S\ref{ss:approximation}).
