\section{A Machine Model for Line-rate Switches}
\label{s:absmachine}

\begin{figure*}[!t]
  \includegraphics[width=\textwidth]{pisa.pdf}
  \caption{The \absmachine machine model and its relationship to
  programmable switch architectures.}
  \label{fig:switch}
\end{figure*}

This section describes \absmachine, a machine model for programmable line-rate
switches that serves as the compiler target for \pktlanguage programs.
\absmachine is inspired by recent programmable switch architectures such as
RMT~\cite{rmt}, Intel's FlexPipe~\cite{flexpipe}, and Cavium's XPliant Packet
Architecture~\cite{xpliant}. \absmachine abstracts these architectures and
extends them with stateful processing units which are used to implement
data-plane algorithms. These processing units, called {\em atoms}, precisely
model the set of operations that a hardware target can execute at line-rate,
and act as the low-level instruction set for the \pktlanguage compiler.

\subsection{Programmable switch architectures}
Packets arriving to a programmable switch~(Figure~\ref{fig:switch})
are parsed by a programmable parser that turns packets into header
fields. These header fields are first processed by an ingress pipeline
consisting of match-action tables arranged in stages. Processing a
packet at a stage may modify its header fields as well as some
persistent state at that stage. Each stage only has access to its
own local state. To share state between stages, it must be carried in
packet headers.

Following the ingress pipeline, the packet is queued. Once the packet
is dequeued by the switch scheduler, it is processed by a similar
egress pipeline before being transmitted.

To reduce chip area, the ingress and egress pipelines are shared
across switch ports.  Each pipeline needs to handle aggregate traffic
belonging to all ports on the switch, at all packet sizes.  For
instance, a 64-port switch with port speeds of 10 Gigabits/second and
a minimum packet size of 64 bytes needs to process around a billion
packets per second~\cite{rmt}.  Equivalently, with a clock frequency
of 1 GHz, each pipeline stage needs to process one packet every clock
cycle (1 ns).  The need to handle one packet per clock cycle is
typical because switches are designed for the highest port density and
speed supported by the switching chip. We assume one packet per clock
cycle throughout the paper.\footnote{For concreteness, we assume a 1
  GHz clock frequency.}

Having to process a packet every clock cycle in each stage greatly
curtails the operations that can be performed on each packet. In
particular, any packet operation that modifies state that is visible
to the next packet must finish execution in a single clock cycle (see
\S\ref{s:atoms} for details). Because of this restriction, in
contrast to software routers, programmable switching chips provide a
small set of processing units or primitives for manipulating packets
and state in a stage. These processing units determine what algorithms
can run on the switch at line-rate. 

The technical challenge here is to determine primitives that enable a
broad range of data-plane algorithms to be implemented, and build a
compiler for mapping a user-friendly description of an algorithm to
these low-level primitives.
\subsection{The \absmachine machine model}

\absmachine (the bottom half of Figure~\ref{fig:switch}) models a switch
pipeline such as the ingress or egress pipeline. A pipeline in \absmachine
consists of a number of stages executing synchronously on every clock cycle. An
incoming packet is processed by each stage and handed off to the next, until it
exits the pipeline. Each stage processes a packet every clock cycle, which in
our case is 1 ns. \absmachine only models components pertinent to data-plane
algorithms.  It models the computation within a match-action table in a stage
(i.e., the action half of the match-action table), but not the match semantics
(e.g., direct, or ternary) (we discuss embedding these actions in a standard
match-action pipeline in \S\ref{ss:guards}). \absmachine does not model packet
parsing and assumes that packets arriving to it are already parsed.

\subsection{Atoms: \absmachine's processing units}
\label{ss:atoms}

In \absmachine, each pipeline stage contains a vector of
\textit{atoms}. All atoms in this vector execute in parallel on every
clock cycle.  Informally, an atom is an atomic unit of packet processing
supported natively by a \absmachine machine. Atoms can optionally
modify persistent state stored on the switch and constitute the
machine's instruction set.  In contrast to instruction sets for CPUs,
GPUs, DSPs, and NPUs, the atoms for a \absmachine machine need to be
substantially richer to enable useful operations at line-rate. We
explain this through an example below.

Let us assume we need to atomically increment a state variable stored
on the switch to count packets. Naively, this can be done with
hardware support for three simple single-cycle operations: \textit{reading} some
memory in the first clock cycle, \textit{adding} one in the next, and
\textit{writing} it to memory in the third. However, this doesn't
provide atomicity. To see why, assume packet 1 increments the counter
from 0 to 1 by transiting the read, add, and write stages at clock cycles 1,
2, and 3 respectively.  If packet 2 issues the read at time
2, it will increment the counter again from 0 to 1, when it should be
2. Locks are a potential solution. However, locking causes
packet 2 to wait during packet 1's increment, and the switch no longer
sustains line rate on one packet every clock cycle, which it is expected to
regardless of the input workload.\footnote{Wait-free objects~\cite{herlihy_wait} are an
  alternative to locking, but are typically too complicated for
  hardware.}

In this architecture, the only way to provide an atomic increment is
to expressly support it in hardware by reading memory, incrementing it
and writing it back in a single stage within one clock cycle. The same
observation applies to any line-rate atomic operation---not just an
increment.  This motivate our representation of atoms as a body of
sequential code. An atom completes execution of the entire body of
code and modifies a packet before processing the next packet.  An atom
may also contain internal state that is local to that atom alone and
persists across packets.

Using this representation, a switch counter that wraps around at 100
can be written as the atom below.\footnote{We use {\tt p.x} to
  represent field {\tt x} within a packet {\tt p} and {\tt x} to
  represent a state variable {\tt x} that persists across packets.}
\begin{lstlisting}[style=customc, numbers=none, frame=none]
if (counter < 99)
  counter++;
else
  counter = 0;
\end{lstlisting}
Similarly, a stateless operation like setting a packet field (e.g. P4's {\tt
modify\_field} primitive~\cite{p4spec}) can be written as the atom:
\begin{lstlisting}[style=customc, numbers=none, frame=none]
  p.field = value;
\end{lstlisting}
Table~\ref{tab:templates} provides more examples of atoms.

We note that---unlike stateful atomic operations such as increment
that modify persistent state--- stateless operations can be supported
by providing a set of basic stateless operations such as packet field
arithmetic. Consider, for instance, the operation pkt.f1 = pkt.f2 +
pkt.f3 - pkt.f4. Because this operation doesn't modify state that is
visible to the next packet, it can be implemented by adding in one
pipeline stage / clock cycle, and then subtracting in the next, unlike the increment.
\subsection{Constraining atoms}
\label{s:atomConstraints}

\paragraph{Computational limits}
To provide line-rate performance, atom bodies must be suitably
constrained.  When implemented in digital logic, the atom body must
finish execution within one clock cycle (1 ns for a 1 GHz clock
frequency). We constrain atom bodies by defining {\it atom templates}
(\S\ref{ss:code_gen}).  An atom template is a program that always
terminates and specifies exactly how the atom is executed. One example
is an ALU with a restricted set of primitive operations to choose from
(Figure~\ref{fig:alu_diag}). Atom templates allow us to create
\absmachine machines with different atoms.  In practice, atom
templates will be designed by an ASIC engineer and exposed as a
machine's instruction set~(\S\ref{ss:targets}).  As programmable
switches evolve, atoms will evolve as well.  However, atoms cannot be
arbitrarily complex: the line rate is inversely proportional to an
atom's execution latency~(\S\ref{ss:perfprog}).

\begin{figure}[h]
  \begin{minipage}{0.4\columnwidth}
  \begin{center}
  \includegraphics[width=\columnwidth]{circuit.pdf}
  \end{center}
  \caption{Circuit for an atom that can add or subtract a constant from a state variable.}
  \label{fig:alu_diag}
  \end{minipage}
  \hspace{0.05\columnwidth}
  \begin{minipage}{0.55\columnwidth}
  \begin{lstlisting}
  bit choice = ??;
  int constant = ??;
  if (choice) {
    x = x + constant;
  } else {
    x = x - constant;
  }
  \end{lstlisting}
  \caption{Circuit representation as an atom template.}
  %Each ``??(n)'' represents a hole that can be filled in with values in $[0, 2^n -1]$.}
  \label{fig:alu_in_sketch}
  \end{minipage}
\end{figure}

\paragraph{Resource limits}

For any real machine, we also need to limit the number of atoms
in each stage (\textit{pipeline width}) and the number of stages in the
pipeline (\textit{pipeline depth}). This is similar to the limits on the
number of stages, number of tables per stage, and amount of memory per
stage in programmable switch architectures such as RMT and
FlexPipe~\cite{lavanya_compiler}.

\subsection{What can \absmachine not do?}
\label{ss:limitations}

\absmachine is a good fit for data-plane algorithms that do a small amount of
work per packet and manipulate only packet headers. Data-plane algorithms like
deep packet inspection and WAN optimization access packet payloads. These
algorithms require a switch to parse the packet payload as well---effectively
parsing a huge header consisting of each byte in the packet payload. Parsing
deep parse graphs is challenging at line rates of 1 GHz.

\absmachine is ideally suited to algorithms that carry out small computations
on a small amount of state frequently, e.g., setting a bit or conditionally
incrementing a counter. Some algorithms run infrequently (every few
microseconds, as opposed to line rate (nanosecond)), but either access large
quantities of state or require complex computations. An example would be
periodically dividing the total number of transmitted bytes by a time interval
to compute the link rate, as RCP does.
%TODO: periodic scan for CONGA, give example.
