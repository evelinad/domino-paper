\newpage
\section{Introduction}
\label{s:intro}
Network switches in modern datacenters, enterprises, and service-provider
networks perform many tasks in addition to standard packet forwarding. The set
of requirements for switches has only increased with time as network operators
seek greater control over performance.  Performance may be improved using both
data-plane and control-plane mechanisms. This paper focuses on data-plane
algorithms. These algorithms process and transform packets, creating and
maintaining state in the switch. Examples include active queue
management~\cite{red,avq,codel}, scheduling~\cite{pifo_hotnets}, congestion
control with switch feedback~\cite{xcp, rcp}, network
measurement~\cite{opensketch, bitmap_george}, and data-plane traffic
engineering~\cite{conga}.

An important requirement for data-plane algorithms is the ability to process
packets at the switch's line rate: 10--100 Gbit/s on 10--100 ports.  Therefore,
these algorithms are typically implemented using dedicated hardware.  Hardware
designs are rigid and not reconfigurable in the field. Thus, implementing and
deploying a new algorithm, or even modifying a deployed one, requires an
investment in new hardware---a time-consuming and expensive proposition.

This rigidity affects many stakeholders adversely: vendors~\cite{cisco_nexus,
dell_force10, arista_7050} building network switches with merchant-silicon
chips~\cite{trident, tomahawk, mellanox}, network operators deploying these
switches~\cite{google,facebook,vl2}, and researchers developing new data-plane
algorithms~\cite{rcp, conga, xcp, bitmap_george}.

To run data-plane algorithms after a switch has been built, researchers and
companies have attempted to build programmable switches for many years,
starting from efforts on active networks~\cite{active-nets} to network
processors~\cite{ixp4xx} to software routers~\cite{click, dpdk}. All these
efforts sacrificed performance for programmability, typically running an order
of magnitude (or worse) slower than hardware line rates. Unfortunately, this
reduction in performance has meant that these systems are rarely deployed in
production networks.

Programmable switching chips~\cite{flexpipe, xpliant, tofino} competitive in
performance with state-of-the-art fixed-function chips~\cite{trident,
tomahawk, mellanox} are now becoming available. These chips implement a few
low-level hardware primitives that can be configured by software into a
processing pipeline, and are field-reconfigurable. Building a switch with such
a chip is attractive because it does not compromise on data rates~\cite{rmt}.

In terms of programmability, these chips today allow the network operator to
program packet parsing and forwarding, i.e., a programmer can program the set
of protocol formats to be matched and the set of actions to be executed when
matching packet headers in a match-action table. Languages such as P4~\cite{p4}
are emerging as a way to express such {\em match-action processing} in a
hardware-independent manner.

There is a gap between this form of programmability and the needs of data-plane
algorithms. By contrast to packet forwarding, which doesn't modify state in the
data plane, many data-plane algorithms create and modify {\em algorithmic
state} in the switch as part of packet processing.

% TODO: Run this by Hari.
For such algorithms, programmability must directly capture the algorithm's
intent without requiring the algorithm to be shoehorned into hardware
primitives like a sequence of match-action tables. Indeed, the ability to
directly capture an algorithm's intent pervades programming models for many
other networking devices, e.g., software routers~\cite{click}, network
processors~\cite{packetc}, and network endpoints~\cite{qdisc}.

By studying the requirements of data-plane algorithms and the constraints of
line-rate hardware, we introduce a new abstraction to program and implement
data-plane algorithms: a {\em packet transaction} (\S\ref{s:transactions}). A
packet transaction is a sequential code block that is atomic and isolated from
other such code blocks, i.e., any visible state is equivalent to a serial
execution of packet transactions across packets in the order of packet
arrival.  Packet transactions allow the programmer to focus on the operations
needed for each packet without worrying about other concurrent packets.

Packet transactions have an \textit{all-or-nothing} guarantee: all packet
transactions accepted by the packet transactions compiler will run at line
rate, or be rejected.  There is no ``slippery slope'' of running network
algorithms at lower speeds as with network processors or software routers: when
compiled, a packet transaction runs at line rate, or not at all.  Performance
is not just predictable, but guaranteed.

In realizing packet transactions, we make three new contributions.  First, {\em
\absmachine}, a machine model for programmable line-rate
switches~(\S\ref{s:absmachine}).  \absmachine models two important constraints
(\S\ref{s:atomConstraints}) for stateful line-rate operations: the inability to
share state between different packet-processing units, and the requirement that
any switch state modifications be visible to the next packet entering the
switch. Based on these constraints, we introduce {\em atoms} to represent a
programmable switch's packet-processing units, i.e., its instruction set.

Second, {\em \pktlanguage{}}, a new domain-specific language (DSL) for
data-plane algorithms, with packet transactions at its core
(\S\ref{s:transactions}).  \pktlanguage is an imperative language with C-like
syntax, to our knowledge the first to offer such a high-level programming
abstraction for line-rate switches.

Third, {\em a compiler from \pktlanguage packet transactions to a \absmachine
target}~(\S\ref{s:compiler}). The \pktlanguage compiler extracts {\em codelets}
from  transactions: code fragments, which if executed atomically, guarantee a
packet transaction's semantics. It then uses program
synthesis~\cite{sketch_asplos} to map codelets to atoms, rejecting the
transaction if the atom cannot execute the codelet.

We evaluate expressiveness by programming a variety of data-plane algorithms
(Table~\ref{tab:algos}) in \pktlanguage and compare with P4. We find that
\pktlanguage provides a more concise and natural programming model for stateful
data-plane algorithms.  Next, because no existing programmable switch supports
the set of atoms required for our data-plane algorithms, we design a set of
compiler targets for these algorithms based on \absmachine
(\S\ref{ss:targets}).  We show that these targets are feasible in a 32-nm
standard-cell library with $< 2\%$ cost in area relative to a 200
\si{\milli\metre\squared} baseline switching chip~\cite{gibb_parsing}.
Finally, we compile data-plane algorithms written in \pktlanguage to these
targets (\S\ref{ss:compiler}) to show how a target's atoms determine the
algorithms it can support. We conclude with several lessons for programmable
switch design (\S\ref{ss:lessons}).

Code for the \pktlanguage compiler, the \absmachine machine model, and the code
examples listed in Table~\ref{tab:algos} is available at
\url{http://web.mit.edu/domino}.
