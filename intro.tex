\section{Introduction}
\label{s:intro}

Data-plane algorithms~\cite{cestan} are algorithms that are implemented within
a network switch. These algorithms process every data packet that passes
through the switch, transforming the packet and/or state of the switch itself.
Examples of such algorithms include congestion-control that uses feedback from
switches~\cite{xcp, rcp, pdq, dctcp}, active queue management~\cite{codel},
network measurement~\cite{opensketch, bitmap_george, elephant_george}, and
load-balanced routing in the data plane~\cite{conga}.

Because data-plane algorithms process every packet, an important requirement is
the ability to run at the switch's line rate.  As a result, these algorithms
are primarily implemented using dedicated hardware. However, hardware designs
are rigid and inflexible, making it difficult to experiment with new
algorithms.

This rigidity affects network switch vendors that build network
equipment~\cite{cisco_nexus, dell_force10, arista_7050} based on
merchant-silicon switching chips,  network operators using such chips within
private networks~\cite{jupiter,amazon,isp}, and researchers developing new
switch algorithms~\cite{xcp, codel, d3, detail, pdq}. In all cases, the only
way to implement a new data-plane algorithm is to expressly build hardware for
it---a time-consuming and resource-intensive process.

Programmable switching chips~\cite{flexpipe, xpliant, rmt} that are
performance-competitive with state of the art fixed-function
chipsets~\cite{trident, tomahawk, mellanox} have emerged as an alternative.
These chips allow designers to express their algorithms using a domain-specific
language such as P4~\cite{p4}, propreitary SDKs such as the XPliant
SDK~\cite{xpliant_sdk}, or open APIs such as the Switch Abstraction Interface
~\cite{sai}.

These approaches bear a close resemblance to the underlying hardware, forcing
programmers to reason about low-level pipeline semantics and hardware
concurrency, and place a high burden on network programmers who are used to
writing sequential programs in a high-level language (such as C) for software
routers~\cite{click} and network processors~\cite{packetc, ixp, microenginec,
nova}.

%~\cite{http://files.opencompute.org/oc/public.php?service=files&t=10c4eb2695c253e9e2fa58329fd53a82}
% ~\cite{http://www.cavium.com/newsevents-Cavium-XPliant-Switches-and-Microsoft-Azure-Networking-Achieve-SAI-Routing-Interoperability.html}
% There doesn't even exist an alternative besides hardware if there aren't
% languages such as hardware.

% I think PX applies only to FPGAs.  packetC, POF, and all its related cousins
% apply to NPUs only (by and large).  Really, the state-of-the art for
% programmble switching chips is only P4 and proprietary APIs.

% Alvin->Anirudh: Leave out the sentence about P4 alone.
%%As evidence, we point the reader to
%%\url{https://github.com/anirudhSK/p4-semantics}, which documents instances of
%%incorrect P4 code caused by confusion in language semantics.

% Anirudh->Alvin: I am getting rid of this because I now have more direct evidence
% that the sequential + parallel mixup doesn't work, which I presented at the P4
% consortium to get them to switch to sequential.
%%Taken together, this mix of sequential and parallel
%%semantics means that the net effect of even extremely simple P4 programs is
%%hard to state crisply.

%%For instance, simple\_router.p4~\cite{simple_router.p4} is a program that only
%%implements longest-prefix-match IP routing. Its effect, at first glance,
%%is a sequence of two statements: to apply an IPv4 longest prefix match, and
%%then to use the match result  to set the destination MAC address. However,
%%hidden beneath this sequential facade is the fact that the longest prefix match
%%actually executes three operations in parallel: decrementing the IP TTL field,
%%setting the egress port, and the next hop IP address in a switch-internal
%%header.
%%

This paper presents a new DSL, \pktlanguage~(\S\ref{s:language}), for
expressing data-plane algorithms. \pktlanguage is a high-level, imperative
language that allows programmers to express data-plane algorithms using {\em
packet transactions}: sequential blocks of code that run to completion on each
packet and in isolation from other packets executing the same code block.
\pktlanguage is heavily constrained by the capabilities of switch targets: for
instance, it forbids all iterative constructs. Constraining \pktlanguage leads
to a simpler compiler for \pktlanguage~(\S\ref{s:compiler}), relative to
compilers~\cite{ixp} for imperative languages that target more flexible devices
such as network processors and software routers.

The \pktlanguage compiler takes a packet transaction written in \pktlanguage
and generates code for an abstract machine
\absmachine~(\S\ref{ss:abstract_machine}) that represents essential
features of emerging programmable switching architectures.  In particular,
\absmachine introduces \textit{atoms}: sequential code blocks consisting of
multiple packet-processing instructions. These instructions are assumed to
execute atomically: their effect is visible in entirety before the next packet
is processed. Internally, an atom can encapsulate local state that affects the
atom's behavior from packet to packet, e.g.  switch counters.

Using atoms as a building block, \absmachine specifies a switch pipeline as an
atom grid with the horizontal axis representing physical pipeline stages and
the vertical axis representing concurrency within each stage.  By limiting the
number and type of instructions within each atom~(\S\ref{ss:complexity}),
\absmachine models limits on computation in line-rate switches. This allows us
to define a variety of switch pipelines by varying the number of pipeline
stages, the number of atoms within each stage, and computation limits on each atom.
% Btw, our limits can be a little more "non-linear" than the number and type of
% instructions, such as a circuit template.

While existing uses of transactions in databases~\cite{db_trans}, network
processors ~\cite{npus}, and software routers~\cite{click} guarantee isolation,
transaction throughput depends on transaction complexity. Packet transactions,
by contrast, guarantee constant throughput. All packet transactions that are
implementable can run at the switch's line rate, or are rejected by the compiler.
% Alvin: Database transactions have rollback as well.

Expressing data-plane algorithms as packet transactions has an important
practical benefit.  A packet transaction is just one large atom, and hence can
be executed on \absmachine.  Feeding the same test input to both the
user-supplied packet transaction and the pipelined atom grid that implements it
allows us to verify that the outputs match up bit-for-bit. We use this to
develop an automated tester, \tester, that probabilistically verifies the
correctness of compilations in a manner resembling translation
validation~\cite{necula_validation}.

We use \pktlanguage to express several data-plane algorithms such as flowlet
switching~\cite{flowlet}, data-plane bloom filters~\cite{bloom}, heavy-hitter
detection, CoDel~\cite{codel}, and CONGA~\cite{conga}. We determine if they are
implementable, for specific instantiations of \absmachine. In the process, we
provide guidance for how programmable hardware should evolve in the future to
support the needs of data-plane algorithms.  We distill lessons learned in the
process~(\S\ref{s:lessons}) and conclude by placing \pktlanguage in context
with related work and by outlining several areas for future work.
%TODO: I don't quite know what the guidance is yet. Will have it by the weekend.

% Alvin thought this was distracting.
%% design for how \pktlanguage can target P4 as a backend, which would allow
%% developers to run \pktlanguage on any target that supports P4.
