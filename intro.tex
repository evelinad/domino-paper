\section{Introduction}
\label{s:intro}

Data-plane algorithms~\cite{cestan} are algorithms that are implemented within
a network switch. These algorithms process every data packet that passes
through the switch, transforming the packet and/or state stored on the switch.
Examples of such algorithms include congestion-control that uses feedback from
switches~\cite{xcp, rcp, pdq, dctcp}, active queue management~\cite{codel},
network measurement~\cite{opensketch, bitmap_george, elephant_george}, and
load-balanced routing in the data plane~\cite{conga}.

Because data-plane algorithms process every packet, an important implementation
requirement is the ability to process packets at line rate.  Consequently,
these algorithms are primarily implemented using dedicated hardware. However,
hardware designs are rigid, making it difficult to experiment with new
algorithms.

This rigidity affects network switch vendors that build network
equipment~\cite{cisco_nexus, dell_force10, arista_7050} based on
merchant-silicon switching chips~\cite{trident, tomahawk, mellanox}, network
operators using such chips within private networks~\cite{google,facebook,vl2},
and researchers developing new switch algorithms~\cite{xcp, codel, d3, detail,
pdq}. Today, the only way to implement a new data-plane algorithm at line rate
is to expressly build hardware for it---a time-consuming and resource-intensive
process.

Programmable switching chips~\cite{flexpipe, xpliant, rmt} that are
performance-competitive with state of the art fixed-function
chipsets~\cite{trident, tomahawk, mellanox} have emerged as an alternative.
These chips allow designers to express their algorithms using a domain-specific
language (DSL) such as P4~\cite{p4} or propreitary SDKs such as those from
XPliant~\cite{xpliant_sdk, xpliant_sdk2} and Intel~\cite{intel_sdk}.  These
approaches bear a close resemblance to the underlying hardware, forcing
programmers to reason about low-level pipeline semantics and hardware
concurrency, and place a high burden on network programmers who are used to
writing sequential programs in a high-level language (such as C) for software
routers~\cite{click} and network processors~\cite{ixp4xx, ixp2800}.

In this paper, we present \pktlanguage, a new DSL for expressing data-plane
algorithms. Unlike existing approaches, \pktlanguage is a high-level,
imperative language that allows programmers to express data-plane algorithms
using {\em packet transactions} (\S\ref{s:transactions}). To the programmer,
packet transactions provide the abstraction of a sequential block of code that
runs to completion on each packet before executing the same packet transaction
on the next packet. Packet transactions guarantee deterministic performance :
all packet transactions that are implementable can run at the switch's line
rate, or are rejected by the compiler.
% Anirudh->Alvin: Does this sound better?
%%

We have implemented a compiler for \pktlanguage that compiles a packet
transaction written in \pktlanguage and generates code for an abstract machine
called \absmachine~(\S\ref{s:absmachine}), which models essential features of
emerging programmable switch architectures.  In addition, \absmachine
introduces the concept of {\em atoms}. Atoms are sequential code blocks
consisting of multiple packet-processing instructions executed atomically by
\absmachine and provide the underlying hardware support for realizing the
programmer's view of packet transactions.

Informally, an atom captures hardware support for atomic operations such as a
test-and-set~\cite{tas}, compare-and-swap~\cite{cas}, or
fetch-and-add~\cite{faa}, whose effect is visible before the next packet. By
constraining the number and type of instructions within each
atom~(\S\ref{ss:complexity}), \absmachine captures practical limits to atomic
computations that can be carried out at line rate.

%%Internally, an atom can encapsulate local state that
%%affects the atom's behavior from packet to packet to model elements like switch
%%counters. \ac{this is confusing and sounds just the conceptual definition 
%%of transactions that you just mentioned.}
%%\ac{what does atom have to do with state? You also haven't mentioned 
%%the concept of state before this. Is the concept of switch state already  
%%well known?}  
%% Anirudh:Alvin: Commenting out above because state sounds like a diversion now.

%%\ac{I find this confusing. Is this supposedly some tuning parameters that  
%%\absmachine provides that can be used to model different types of switches?}  
% Anirudh-> Alvin: Simplifying the above to something more succinct.

Expressing data-plane algorithms as packet transactions also helps in program
verification.  Conceptually, a packet transaction is just one large atom, and
hence can be executed on \absmachine.  By feeding the same test input to both
the user-supplied packet transaction and its pipelined implementation and
verifying that the outputs match up, an automated tester (\S\ref{s:tester}) can
spot check the correctness of compilations~(\S\ref{s:tester}).
%\ac{Is \tester necessary if we can write
%a proof about correctness of the partitioning algorithm?} 
% Anirudh->Alvin: I think it's important for a pragmatic reason. It helped me
% catch some bugs in compiler passes that I wouldn't have caught otherwise.
% If we had a formally verified compiler then I would agree with you.

%TODO: Explain one real use case for bloom filters. Everyone talks about it but
%I don't seem to know what the real use case is.
To evaluate the usefulness of \pktlanguage, we use \pktlanguage to express
several data-plane algorithms~(\S\ref{s:eval}) such as flowlet
switching~\cite{flowlets}, data-plane bloom filters~\cite{bloom}, heavy-hitter
detection, CoDel~\cite{codel}, and CONGA~\cite{conga}---each in under 60 lines
of \pktlanguage code. For each algorithm, the \pktlanguage compiler determines
if they are implementable, for specific constraints~(\S\ref{ss:complexity})
imposed on the atoms in \absmachine. In the process, we provide guidance for
how programmable hardware should evolve in the future to support the needs of
data-plane algorithms.  We place \pktlanguage in the context of related
work~(\S\ref{s:related}) and conclude by outlining several areas for future
work~(\S\ref{s:future}).
%TODO: I don't quite know what the guidance is yet. Will have it by the
%weekend.
