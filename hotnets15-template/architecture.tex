\section{Problem setup}
\label{s:context}

To motivate our problem, we first describe (\S\ref{ss:dataplane}) the type of
algorithms that we would like \pktlangauage{} to express. We then describe the
architecture (\S\ref{ss:architecture}) of the programmable switches on which
such algorithms would be implemented. We observe that there is a large semantic
gap between the high-level pseudocode style in which these algorithms are
available today and both the low-level hardware details of the switches and the
low-level abstractions provided used by P4 to program them today. This then
leads us naturally to building a compiler to bridge this gap.

\section{The architecture of a programmable switch}
\label{s:architecture}
We briefly describe the architecture of a programmable switch next. For
concreteness, we describe the Reconfigurable Match-Action Table
architecture~\cite{rmt}, although our ideas apply to other pipelined
programmable switch architectures such as Intel's FlexPipe~\cite{flexpipe} and
Cavium's Xpliant~\cite{xpliant} architectures.

Figure~\ref{fig:architecture}, based on Figure 3 from ~\cite{rmt}, provides a
high-level overview of the RMT architecture. Packets enter the switch through
serial links and are handled by a programmable parser that turns packets into a
bag of header fields. The ingress and egress pipelines have a number of
physical pipeline stages that can process these header fields using a sequence
of match-action tables.

These tables match on arbitrary header fields and carry out actions in response
to a match hit.  The actions are built out of simpler action primitives, which
represent simple arithmetic and logic operations on packet fields. To remain
performance competitive with fixed-function switches~\cite{mellanox, broadcom},
each action primitive can modify only one packet field, although several action
primitives can be grouped together into larger actions if they can all execute
in parallel.

The RMT architecture can also carry out a limited set of
atomic stateful operations i.e. operations that allow packets to manipulate
state at data-plane rates, which are atomically updated before the arrival of the next packet.
We summarize a few of these below.\footnote{We use the
symbols x and y to refer to stateful variables and pkt.<> to refer to a packet field.
Everywhere, pkt.field can be substituted for a constant operand.}
\begin{enumerate}
\item Reading and writing stateful variables:
      \texttt{x = pkt.field;} or \texttt{pkt.field = x;}
\item Read, modify, write operations on stateful variables:
      \texttt{x = x + pkt.field;}
\item Predicated stateful operations: \texttt{x = pkt.predicate ? pkt.field : x;}
\item Packed operations on pairs of stateful variables: \texttt{ (x, y) = (x + y, x - y);}
\item Multiply and accumulate a stateful variable: \texttt{ x = x * pkt.field + pkt.field2; }
\end{enumerate}

The RMT architecture is shared-nothing: state variables are local to a
particular stage in the ingress or egress pipeline and cannot be shared across
pipeline stages or across ingress and egress pipelines. This restriction is for
performance reasons: embedded on-chip memory banks can typically support 1
Read-Modify-Write operation per clock cycle~\cite{some_citation_from_memoir}
because building multi-ported RAMs is power and area hungry. If a state
variable needs to be accessed from multiple stages in the same pipeline, the
underlying memory bank would need to support more than 1 Read-Modify-Write.

Instead, the RMT architecture allows information sharing across stages by cloning a packet
and recirculating it back into the pipeline. This way a state variable can be
read in stage x, updated downstream in stage y, and then a cloned packet to
stage x could update the state variable in x. However, this has a cost:
recirculated packets consume pipeline capacity, by taking away capacity from
new data packets.  Further, recirculation latency can be as large as a few
hundred clock cycles.
%TODO: Maybe add a figure here.
