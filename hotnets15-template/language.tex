\section{A Language for data-plane algorithms}
\label{s:language}
 We focus on data-plane algorithms that aren't widely
available on all switches today because of the
considerable engineering effort required for hardware
implementations and the rapidly changing nature of these
algorithms. For instance, load-balancing algorithms such
as CONGA~\cite{conga} are available only on a specific
line of CISCO switches.  Active queue-management
algorithms such as CoDel~\cite{codel} need to be
extensively modified~\cite{pie} to suit the architecture
of a hardware switch.  Explicit congestion-control
algorithms such as RCP~\cite{rcp} and XCP~\cite{xcp}, and
measurement algorithms such as
OpenSketch~\cite{opensketch} have been evaluated only in
FPGA-based platforms.  The ever-growing list of new
algorithms~\cite{pdq, d3, detail} makes it challenging to
commit to a hardware implementation of any of them.

 A closer inspection of these
algorithms shows us that the algorithms are characterized by two distinguishing
features: a reliance on persistant state and an irregular control flow, both of
which make them challenging to implement in hardware and hence in P4 given its
low-level nature.

As previously described, data-plane algorithms are characterized by an
irregular control flow and extensive use of stateful processing. Based on these
observations, this section proposes a language to express these algorithms.

To motivate a language for these algorithms, we first observe that any
data-plane algorithm can be expressed as a function that takes in a single
packet and a set of persistent state variables as input. This function then
runs to completion without interruption, modifying the packet and the
persistent state variables in the process. Further, conceptually, only one
packet is processed by this function at any given instant.

This view of data-plane algorithms suggests a natural way to structure them: as
transactions where a function specifies all the required state manipulation and
control flow required for packet processing. The use of transactions is
widespread in packet processing for software-router platforms. For instance,
Click's Element abstraction~\cite{kohler_thesis} specifies packet processing as
a method invocation that isn't pre-empted.  The Linux qdisc
subsystem~\cite{qdisc} exposes an enqueue and dequeue method that specific
algorithms can implement. Intel's IXP architecture for NPUs uses a construct
resembling transactions called a Packet-Processing Stage
(PPS)~\cite{intel_pldi} to express packet processing code.
% https://github.com/torvalds/linux/blob/master/net/sched/sch_codel.c#L256

Relative to these prior systems, our contribution is in observing that
transactions can be profitably used to express data-plane algorithms for
high-speed line-rate switches as well. Realizing this practically requires us
to design a language that expresses packet processing within the body of the
transaction. A good language would strike the right balance between ease of
expression and ease of implementation. Programmable hardware switches
---although a significant advance over their fixed-function counterparts---are
still very restricted in the processing that they do on every packet. This
restriction is required to remain competitive with fixed-function switches.

Based on these observations, we describe our language for packet processing
(Figure~\ref{fig:language}). Our language is a heavily constrained subset of C
that removes all iterative constructs (while, do-while, for, break, continue),
arrays, heaps, and memory allocation. State variables are represented as global
variables. We permit structures to represent packet processing alone, and immediately
desugar these to scalar variables (\S\ref{s:compiler}).

Forbidding loops and other sources of variable performance like memory
allocation, and array scans allows the user to only express code whose
execution latency can be bounded at compile time.  While this may seem overly
restrictive, this is required for the underlying architecture
(\S\ref{s:architecture}), which has deterministic performance regardless of the
traffic pattern or program being run. This results in a different set of
tradeoffs than what programmers are typically used to: a larger program does
not take longer to run. Instead, it may not run at all or might need to be
approximated until it can run (\S\ref{ss:approximation}).
